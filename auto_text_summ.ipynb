{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case Study: Automatic Text Summarization with NLP\n",
    "\n",
    "##### Background\n",
    "\n",
    "* Text summarization is a crucial task in Natural Language Processing (NLP) that involves creating a short, accurate, and fluent summary of a longer text document. Automatic text summarization can help users quickly understand large volumes of information by extracting the most important points from the text.\n",
    "\n",
    "* In this project, we will implement extractive text summarization using the TextRank algorithm. TextRank is an unsupervised graph-based ranking algorithm inspired by the PageRank algorithm used by Google Search. It identifies the most important sentences in a text by building a graph of sentences and ranking them based on the similarity between sentences.\n",
    "\n",
    "* We will use Python along with the nltk and networkx libraries to build the summarizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/joelfuentes/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/joelfuentes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      " \n",
      "Natural Language Processing (NLP) is a subfield of artificial intelligence that focuses on the interaction between computers and humans through natural language.\n",
      "The ultimate objective of NLP is to read, decipher, understand, and make sense of the human languages in a manner that is valuable.\n",
      "By utilizing NLP, developers can organize and structure knowledge to perform tasks such as automatic summarization, translation, named entity recognition, relationship extraction, sentiment analysis, speech recognition, and topic segmentation.\n",
      "In this rapidly evolving field, advancements are being made continuously, enabling computers to understand and process human language with increasing accuracy.\n",
      "As a result, NLP plays a critical role in supporting applications like voice-operated GPS systems, digital assistants, speech-to-text dictation software, chatbots, and many more.\n",
      "With the ever-growing amount of unstructured data, the importance of NLP continues to rise, making it a key area of research and development in the tech industry.\n",
      "\n",
      "\n",
      "Summary:\n",
      " By utilizing NLP, developers can organize and structure knowledge to perform tasks such as automatic summarization, translation, named entity recognition, relationship extraction, sentiment analysis, speech recognition, and topic segmentation. As a result, NLP plays a critical role in supporting applications like voice-operated GPS systems, digital assistants, speech-to-text dictation software, chatbots, and many more.\n"
     ]
    }
   ],
   "source": [
    "# Sample text for summarization\n",
    "text = \"\"\"\n",
    "Natural Language Processing (NLP) is a subfield of artificial intelligence that focuses on the interaction between computers and humans through natural language.\n",
    "The ultimate objective of NLP is to read, decipher, understand, and make sense of the human languages in a manner that is valuable.\n",
    "By utilizing NLP, developers can organize and structure knowledge to perform tasks such as automatic summarization, translation, named entity recognition, relationship extraction, sentiment analysis, speech recognition, and topic segmentation.\n",
    "In this rapidly evolving field, advancements are being made continuously, enabling computers to understand and process human language with increasing accuracy.\n",
    "As a result, NLP plays a critical role in supporting applications like voice-operated GPS systems, digital assistants, speech-to-text dictation software, chatbots, and many more.\n",
    "With the ever-growing amount of unstructured data, the importance of NLP continues to rise, making it a key area of research and development in the tech industry.\n",
    "\"\"\"\n",
    "\n",
    "# Function to generate a summary of the text\n",
    "def summarize_text(text, summary_ratio=0.3):\n",
    "    # Split text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    total_sentences = len(sentences)\n",
    "    \n",
    "    # Clean and tokenize sentences\n",
    "    stop_words = stopwords.words('english')\n",
    "    sentence_tokens = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "    \n",
    "    # Build the similarity matrix\n",
    "    similarity_matrix = np.zeros((total_sentences, total_sentences))\n",
    "    \n",
    "    for idx1 in range(total_sentences):\n",
    "        for idx2 in range(total_sentences):\n",
    "            if idx1 != idx2:\n",
    "                similarity = sentence_similarity(sentence_tokens[idx1], sentence_tokens[idx2], stop_words)\n",
    "                similarity_matrix[idx1][idx2] = similarity\n",
    "    \n",
    "    # Build the graph and rank sentences using PageRank algorithm\n",
    "    nx_graph = nx.from_numpy_array(similarity_matrix)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    \n",
    "    # Sort sentences by their score\n",
    "    ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
    "    \n",
    "    # Select the top sentences for the summary\n",
    "    summary_length = max(1, int(total_sentences * summary_ratio))\n",
    "    summary_sentences = [ranked_sentences[i][1] for i in range(summary_length)]\n",
    "    \n",
    "    # Combine summary sentences\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    return summary\n",
    "\n",
    "# Function to compute the similarity between two sentences\n",
    "def sentence_similarity(sent1, sent2, stop_words=None):\n",
    "    if stop_words is None:\n",
    "        stop_words = []\n",
    "    \n",
    "    sent1 = [w for w in sent1 if w not in stop_words]\n",
    "    sent2 = [w for w in sent2 if w not in stop_words]\n",
    "    \n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    \n",
    "    # Create word vectors\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "    \n",
    "    # Build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        vector1[all_words.index(w)] += 1\n",
    "    \n",
    "    # Build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        vector2[all_words.index(w)] += 1\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarity = cosine_similarity(vector1, vector2)\n",
    "    return similarity\n",
    "\n",
    "# Function to compute cosine similarity between two vectors\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    \n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "# Generate and print the summary\n",
    "summary = summarize_text(text, summary_ratio=0.4)\n",
    "print(\"Original Text:\\n\", text)\n",
    "print(\"\\nSummary:\\n\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Content Preservation\n",
    "The summary includes sentences that cover the importance of NLP, its applications, and its increasing relevance in technology, effectively capturing the essence of the original text.\n",
    "\n",
    "##### Sentence Selection\n",
    "The algorithm selects sentences that are central to the main topic, based on the similarity between sentences and their connectivity in the graph.\n",
    "\n",
    "##### Coherence\n",
    "The summary maintains logical flow and coherence, although it may not be perfect due to the extractive nature of the method.\n",
    "\n",
    "##### Length Control\n",
    "By adjusting the summary_ratio parameter, you can control the length of the summary. In this example, a ratio of 0.4 means the summary contains approximately 40% of the total sentences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
