{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case Study: NLP Text Classification of News Articles using Scikit-Learn\n",
    "\n",
    "* Text classification is a fundamental task in Natural Language Processing (NLP) that involves assigning categories or labels to text documents. It has applications in spam detection, sentiment analysis, news categorization, and more. In this project, we will build a text classification model to categorize news articles into different topics using Python and the Scikit-Learn library.\n",
    "\n",
    "* We will use the 20 Newsgroups dataset, a popular dataset for experimenting with text classification. The dataset comprises around 18,000 newsgroup posts on 20 different topics, ranging from sports and politics to science and technology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9228\n",
      "\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.92      0.94      0.93       160\n",
      "           comp.graphics       0.83      0.92      0.87       195\n",
      " comp.os.ms-windows.misc       0.91      0.86      0.88       197\n",
      "comp.sys.ibm.pc.hardware       0.82      0.88      0.85       196\n",
      "   comp.sys.mac.hardware       0.92      0.90      0.91       193\n",
      "          comp.windows.x       0.92      0.93      0.92       198\n",
      "            misc.forsale       0.85      0.87      0.86       195\n",
      "               rec.autos       0.94      0.94      0.94       198\n",
      "         rec.motorcycles       0.98      0.96      0.97       199\n",
      "      rec.sport.baseball       0.96      0.97      0.97       199\n",
      "        rec.sport.hockey       0.98      0.97      0.97       200\n",
      "               sci.crypt       0.98      0.95      0.96       198\n",
      "         sci.electronics       0.90      0.90      0.90       197\n",
      "                 sci.med       0.94      0.97      0.96       198\n",
      "               sci.space       0.97      0.96      0.97       197\n",
      "  soc.religion.christian       0.90      0.96      0.93       199\n",
      "      talk.politics.guns       0.93      0.92      0.92       182\n",
      "   talk.politics.mideast       0.99      0.96      0.98       188\n",
      "      talk.politics.misc       0.93      0.91      0.92       155\n",
      "      talk.religion.misc       0.94      0.67      0.79       126\n",
      "\n",
      "                accuracy                           0.92      3770\n",
      "               macro avg       0.92      0.92      0.92      3770\n",
      "            weighted avg       0.92      0.92      0.92      3770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all', shuffle=True, random_state=42)\n",
    "\n",
    "# Extract features and labels\n",
    "X = newsgroups.data\n",
    "y = newsgroups.target\n",
    "target_names = newsgroups.target_names\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "\n",
    "# Fit and transform the training data, transform the test data\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the classifier\n",
    "classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### High-Performing Categories\n",
    "Some categories achieve over 90% precision and recall, suggesting that the model can distinguish these topics effectively.\n",
    "\n",
    "##### Confusion Between Categories\n",
    "Lower scores in certain categories may indicate confusion between similar topics (e.g., ‘comp.sys.mac.hardware’ vs. ‘comp.sys.ibm.pc.hardware’).\n",
    "\n",
    "##### Overall Performance\n",
    "An overall accuracy of around 92% is generally considered good for text classification tasks with multiple classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
